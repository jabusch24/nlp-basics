{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c4-named_entity_data challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Challenge Introduction\n",
    "This particular notebook deals with the challenge of creating \"named entity data\".<br>\n",
    "<br>\n",
    "**DISCLAIMER:**<br>\n",
    "This challenge is different to the other challenges as it does not include any actual coding, it's more of a trivial task that just needs to be done, thus, **if you work on this, make sure to submit your intermediate steps as quick as possible in order to avoid redundant efforts!** <br>\n",
    "**INTRO:** Named entities are an essential part of our language. Wikipedia says: *In information extraction, a named entity is a real-world object, such as persons, locations, organizations, products, etc., that can be denoted with a proper name.* Examples are *New York City*, *Aspirin* or *Pfizer Inc*. Identifying those named entities is an important task when trying to understand language systematically. <br>\n",
    "**BAYRON:**<br>\n",
    "One of our goals is to capture the expertise of a person in the best and most natural way possible. It is possible to capture expertise with generic words only, however, we can get far more precise in the real world with the use of named entities. For example, \"I work at McDonald's in Berlin\" gives much more insights than \"I work at a restaurant company in a big city\". If we were to understand named entities just like we understand generic words (\"Berlin\" vs \"City), we could get a much better picture of our experts.<br>\n",
    "**DEEP LEARNING:**<br>\n",
    "Named entity recognition is a pretty old discipline in NLP. Most recently, the evolution of deep neural networks has enabled slim and well performing models. Basically what happens is that a deep neural network is confronted with a large corpus of text and needs to guess which words are named entities, e.g. company names, and which are not. The network then runs through the corpus over and over again to adjust its values and recognize patterns in the sentences. Ideally as a result we get a model that perfectly predicts whether a word is a company name or not. **What we need, however, is a set of predefined named entities to begin with.**<br>\n",
    "**OUTPUT:** <br>\n",
    "Data type: list with tuples<br>\n",
    "Example: [\"software\":\"excel\", \"software\": \"powerpoint\"]<br> \n",
    "At Bayron, we have a couple of predefined named entities that we would like to learn about a person. The following are just proposals and open for discussion. You're welcome to propose your own ideas of named entities. <br>\n",
    "We suggest to begin with the named entities of \"Software\", \"Scientific Discipline\" and \"Job positions\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Start coding\n",
    "I provide some examples analyzed by spaCy's named entity recognizer (NER) and ultimately the three lists with some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"Johnny Depp was the CEO of Acting Stars Inc. from 2014 until 2018.\"\n",
    "doc = nlp(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "# As we can see, spacy is already pretty good at predicting People and Dates. spacy gets much better if more text is supplied rather  \n",
    "# than just a sentence. We want some more specific named entities, thus let's just create them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"GPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "software = [\"powerpoint\",\"excel\",\"sap\",\"eclipse\",\"atom\",\"jupyter\"]\n",
    "science = [\"biology\",\"oncology\",\"hematology\",\"engineering\",\"computer science\",\"theology\",\"medicine\",\"business\"]\n",
    "position = [\"CEO\",\"manager\",\"research scientist\",\"computer scientist\",\"assistant\",\"head\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you're done you could transform the single lists into a list of tuples, e.g. for the software list:\n",
    "named_entity = []\n",
    "for term in software:\n",
    "    named_entity.append((\"software\", term))\n",
    "named_entity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
